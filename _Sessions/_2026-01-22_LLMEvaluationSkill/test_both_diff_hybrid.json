{
  "summary": {
    "method": "hybrid",
    "total_files": 2,
    "exact_match": false,
    "avg_similarity": 0.6411,
    "max_distance": 0.3589,
    "judge_usage": {
      "model": "gpt-4o",
      "total_input_tokens": 674,
      "total_output_tokens": 48,
      "calls": 1
    }
  },
  "input_files": [
    {
      "path": "test_hybrid\\run1_both_diff.md",
      "size_bytes": 653
    },
    {
      "path": "test_hybrid\\run2_both_diff.md",
      "size_bytes": 672
    }
  ],
  "comparison": {
    "files": [
      "run1_both_diff.md",
      "run2_both_diff.md"
    ],
    "exact_match": false,
    "pairwise": [
      {
        "a": "run1_both_diff.md",
        "b": "run2_both_diff.md",
        "distance": 0.3589,
        "similarity": 0.6411,
        "diff_lines": 17
      }
    ],
    "avg_similarity": 0.6411,
    "max_distance": 0.3589,
    "text": {
      "method": "levenshtein",
      "avg_similarity": 0.5087
    },
    "images": {
      "method": "llm-judge",
      "model": "gpt-4o",
      "avg_similarity": 0.6,
      "figures": [
        {
          "figure": "Figure 1",
          "score": 0.6,
          "differences": [
            "color description differs",
            "shape interpretation varies",
            "reconstruction hints differ",
            "labeling of steps differs"
          ]
        }
      ],
      "usage": {
        "input_tokens": 674,
        "output_tokens": 48,
        "calls": 1
      }
    }
  },
  "generated": "2026-01-24T20:20:18.075642+00:00"
}