<transcription_page_header>OpenAI Platform | Pricing</transcription_page_header>

# Pricing

## Text tokens

Prices per 1M tokens.

<!-- Section 1 -->
<!-- Column 1 -->
**Left navigation (site menu)**

Label items:
: Get started
: **Overview**
: **Quickstart**
: **Models**
: **Pricing**
: **Libraries**
: **Docs MCP**
: **Latest: GPT-5.2**

Core concepts:
: **Text generation**
: **Code generation**
: **Images and vision**
: **Audio and speech**
: **Structured output**
: **Function calling**
: **Responses API**

Agents:
: **Overview**
: **Build agents**
: **Deploy in your product**
: **Optimize**
: **Voice agents**

Tools:
: **Cookbook**
: **Forum**

<!-- Column 2 -->
**Main content**

Tabs:
: Batch | Flex | **Standard** | Priority  (Standard tab selected)

<!-- Section 2 -->
Below is the pricing table shown on the page.

<transcription_table>
**Table 1: Text tokens pricing (Prices per 1M tokens)**

| MODEL | INPUT | CACHED INPUT | OUTPUT |
|-------|-------:|-------------:|-------:|
| gpt-5.2 | $1.75 | $0.175 | $14.00 |
| gpt-5.1 | $1.25 | $0.125 | $10.00 |
| gpt-5 | $1.25 | $0.125 | $10.00 |
| gpt-5-mini | $0.25 | $0.025 | $2.00 |
| gpt-5-nano | $0.05 | $0.005 | $0.40 |
| gpt-5.2-chat-latest | $1.75 | $0.175 | $14.00 |
| gpt-5.1-chat-latest | $1.25 | $0.125 | $10.00 |
| gpt-5-chat-latest | $1.25 | $0.125 | $10.00 |
| gpt-5.2-codex | $1.75 | $0.175 | $14.00 |
| gpt-5.1-codex-max | $1.25 | $0.125 | $10.00 |
| gpt-5.1-codex | $1.25 | $0.125 | $10.00 |
| gpt-5-codex | $1.25 | $0.125 | $10.00 |
| gpt-5.2-pro | $21.00 | - | $168.00 |
| gpt-5-pro | $15.00 | - | $120.00 |
| gpt-4.1 | $2.00 | $0.50 | $8.00 |
| gpt-4.1-mini | $0.40 | $0.10 | $1.60 |
| gpt-4.1-nano | $0.10 | $0.025 | $0.40 |
| gpt-4o | $2.50 | $1.25 | $10.00 |
| gpt-4o-2024-05-13 | $5.00 | - | $15.00 |
| gpt-4o-mini | $0.15 | $0.075 | $0.60 |

<transcription_json>
{"table_type":"data_table","title":"Text tokens pricing (Prices per 1M tokens)","columns":["MODEL","INPUT","CACHED INPUT","OUTPUT"],"data":[{"MODEL":"gpt-5.2","INPUT":1.75,"CACHED_INPUT":0.175,"OUTPUT":14.00},{"MODEL":"gpt-5.1","INPUT":1.25,"CACHED_INPUT":0.125,"OUTPUT":10.00},{"MODEL":"gpt-5","INPUT":1.25,"CACHED_INPUT":0.125,"OUTPUT":10.00},{"MODEL":"gpt-5-mini","INPUT":0.25,"CACHED_INPUT":0.025,"OUTPUT":2.00},{"MODEL":"gpt-5-nano","INPUT":0.05,"CACHED_INPUT":0.005,"OUTPUT":0.40},{"MODEL":"gpt-5.2-chat-latest","INPUT":1.75,"CACHED_INPUT":0.175,"OUTPUT":14.00},{"MODEL":"gpt-5.1-chat-latest","INPUT":1.25,"CACHED_INPUT":0.125,"OUTPUT":10.00},{"MODEL":"gpt-5-chat-latest","INPUT":1.25,"CACHED_INPUT":0.125,"OUTPUT":10.00},{"MODEL":"gpt-5.2-codex","INPUT":1.75,"CACHED_INPUT":0.175,"OUTPUT":14.00},{"MODEL":"gpt-5.1-codex-max","INPUT":1.25,"CACHED_INPUT":0.125,"OUTPUT":10.00},{"MODEL":"gpt-5.1-codex","INPUT":1.25,"CACHED_INPUT":0.125,"OUTPUT":10.00},{"MODEL":"gpt-5-codex","INPUT":1.25,"CACHED_INPUT":0.125,"OUTPUT":10.00},{"MODEL":"gpt-5.2-pro","INPUT":21.00,"CACHED_INPUT":null,"OUTPUT":168.00},{"MODEL":"gpt-5-pro","INPUT":15.00,"CACHED_INPUT":null,"OUTPUT":120.00},{"MODEL":"gpt-4.1","INPUT":2.00,"CACHED_INPUT":0.50,"OUTPUT":8.00},{"MODEL":"gpt-4.1-mini","INPUT":0.40,"CACHED_INPUT":0.10,"OUTPUT":1.60},{"MODEL":"gpt-4.1-nano","INPUT":0.10,"CACHED_INPUT":0.025,"OUTPUT":0.40},{"MODEL":"gpt-4o","INPUT":2.50,"CACHED_INPUT":1.25,"OUTPUT":10.00},{"MODEL":"gpt-4o-2024-05-13","INPUT":5.00,"CACHED_INPUT":null,"OUTPUT":15.00},{"MODEL":"gpt-4o-mini","INPUT":0.15,"CACHED_INPUT":0.075,"OUTPUT":0.60}],"unit":"USD per 1M tokens"}
</transcription_json>

<transcription_notes>
- Table is the central pricing table under the "Standard" tab.
- Units: USD (prices shown are per 1M tokens).
- Cached input shows reduced cost for cached prompts; some models show '-' where cached input does not apply.
- Visual layout: three-column pricing table (INPUT, CACHED INPUT, OUTPUT) with the MODEL column on the left. Row separators are thin grey lines. Active tab ("Standard") appears highlighted; other tabs (Batch, Flex, Priority) are unselected.
- Left column (site navigation) and right column (secondary navigation) are present on the page; this table occupies the main central column.
</transcription_notes>
</transcription_table>

<!-- Section 3 -->
<!-- Column 1 -->
**Right sidebar**

> **Sidebar: Text tokens**
> Text tokens
> Image tokens
> Audio tokens
> Fine tuning
> Built-in tools
> Transcription and speech generation
> Image generation
> Embeddings
> Moderation
> Legacy models

<!-- Decorative: Logo (OpenAI) -->
<transcription_page_footer>[unclear: page number?] | OpenAI</transcription_page_footer>